{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shortest_Paths.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHah0H1YIYy5eZ1qLeCTfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fkonrad97/Network/blob/main/Shortest_Paths.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J5XbskhNTTj"
      },
      "source": [
        "from collections import defaultdict\n",
        "from math import log, e\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from sys import maxsize\n",
        "from collections import deque\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq-kgfqdNXq-"
      },
      "source": [
        "# Print out the 'list' to the 'name.csv' file \n",
        "\n",
        "def printOut(name, list):\n",
        "    with open(name + '.csv', 'w', newline='') as csv_1:\n",
        "        csv_out = csv.writer(csv_1)\n",
        "        csv_out.writerows([list[index]] for index in range(0, len(list)))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCjLiPwLNZZF"
      },
      "source": [
        "# Read positions of nodes (X,Y,Z)\n",
        "\n",
        "def positionRead(name):\n",
        "    positions = pd.read_csv(name + \".csv\", header=None, sep=\";\")\n",
        "    # Remove a plus sign from the end of the number\n",
        "    positions[0][0] = positions[0][0][:-1]\n",
        "    positions[0] = positions[0].astype(float)    # Convert data to numerical value\n",
        "    return positions"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnyCgZSNd7C"
      },
      "source": [
        "# Read connection table between nodes\n",
        "\n",
        "def connectionRead(name):\n",
        "    connections = pd.read_csv(name + \".csv\", header=None)\n",
        "    return connections"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ube6zpo4NeTo",
        "outputId": "965ebac0-8912-4966-de0f-e7d892d627f7"
      },
      "source": [
        "# List of the positions of nodes\n",
        "# positions = positionRead(\"Network/Brain_data/Brain1Positions\")\n",
        "positions = positionRead(\"/content/Brain1Positions\")\n",
        "\n",
        "# List of how nodes connected to each other\n",
        "# connections = connectionRead(\"Network/Brain_data/Brain1Connections\")\n",
        "connections = connectionRead(\"/content/Brain1Connections\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-64-b785f2d6c68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# List of the positions of nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# positions = positionRead(\"Network/Brain_data/Brain1Positions\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositionRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/Brain1Positions\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# List of how nodes connected to each other\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-62-7dfc97cb697f>\u001b[0m in \u001b[0;36mpositionRead\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpositionRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Remove a plus sign from the end of the number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpositions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/Brain1Positions.csv does not exist: '/content/Brain1Positions.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8nLsgNnCamC"
      },
      "source": [
        "# Entropy by numpy library\n",
        "\n",
        "def entropy(labels, base=None):\n",
        "    n_labels = len(labels)\n",
        "    \n",
        "    if n_labels <= 1:\n",
        "        return 0\n",
        "    \n",
        "    value, counts = np.unique(labels, return_counts=True)\n",
        "    probs = counts/n_labels\n",
        "    n_classes = np.count_nonzero(probs)\n",
        "    \n",
        "    if n_classes <= 1:\n",
        "        return 0\n",
        "    \n",
        "    ent = 0.\n",
        "    \n",
        "    base = e if base is None else base\n",
        "    for i in probs:\n",
        "        ent -= i * log(i, base)\n",
        "        \n",
        "    return ent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qXMCz1WOmGZ"
      },
      "source": [
        "paths = []\n",
        "\n",
        "for i in range(len(connections)):\n",
        "  src = i\n",
        "  dest = 0\n",
        "  route = []\n",
        "  for j in connections[i]:\n",
        "    if j == 1 and src < dest:\n",
        "      route.append([src,dest])\n",
        "    dest += 1\n",
        "  paths.append(route)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkTx-mG0Nn4_"
      },
      "source": [
        "# Function to form edge between\n",
        "# two vertices src and dest\n",
        " \n",
        "def add_edge(adj: List[List[int]],\n",
        "             src: int, dest: int) -> None:\n",
        "    adj[src].append(dest)\n",
        "    adj[dest].append(src)\n",
        "\n",
        "# Function which finds all the paths\n",
        "# and stores it in paths array\n",
        "def find_paths(paths: List[List[int]], path: List[int],\n",
        "               parent: List[List[int]], n: int, u: int) -> None:\n",
        "    # Base Case\n",
        "    if (u == -1):\n",
        "        paths.append(path.copy())\n",
        "        return\n",
        " \n",
        "    # Loop for all the parents\n",
        "    # of the given vertex\n",
        "    for par in parent[u]:\n",
        " \n",
        "        # Insert the current\n",
        "        # vertex in path\n",
        "        path.append(u)\n",
        " \n",
        "        # Recursive call for its parent\n",
        "        find_paths(paths, path, parent, n, par)\n",
        " \n",
        "        # Remove the current vertex\n",
        "        path.pop()\n",
        "\n",
        "# Function which performs bfs\n",
        "# from the given souce vertex\n",
        "def bfs(adj: List[List[int]],\n",
        "        parent: List[List[int]], n: int,\n",
        "        start: int) -> None:\n",
        " \n",
        "    # dist will contain shortest distance\n",
        "    # from start to every other vertex\n",
        "    dist = [maxsize for _ in range(n)]\n",
        "    q = deque()\n",
        " \n",
        "    # Insert source vertex in queue and make\n",
        "    # its parent -1 and distance 0\n",
        "    q.append(start)\n",
        "    parent[start] = [-1]\n",
        "    dist[start] = 0\n",
        " \n",
        "    # Untill Queue is empty\n",
        "    while q:\n",
        "        u = q[0]\n",
        "        q.popleft()\n",
        "        for v in adj[u]:\n",
        "            if (dist[v] > dist[u] + 1):\n",
        " \n",
        "                # A shorter distance is found\n",
        "                # So erase all the previous parents\n",
        "                # and insert new parent u in parent[v]\n",
        "                dist[v] = dist[u] + 1\n",
        "                q.append(v)\n",
        "                parent[v].clear()\n",
        "                parent[v].append(u)\n",
        " \n",
        "            elif (dist[v] == dist[u] + 1):\n",
        " \n",
        "                # Another candidate parent for\n",
        "                # shortes path found\n",
        "                parent[v].append(u)\n",
        " \n",
        "# Function which prints all the paths\n",
        "# from start to end\n",
        "def getPaths(adj: List[List[int]], n: int,\n",
        "                start: int, end: int) -> None:\n",
        "    revPaths = []\n",
        "    path = []\n",
        "    parent = [[] for _ in range(n)]\n",
        "\n",
        "    paths = []\n",
        " \n",
        "    # Function call to bfs\n",
        "    bfs(adj, parent, n, start)\n",
        " \n",
        "    # Function call to find_paths\n",
        "    find_paths(revPaths, path, parent, n, end)\n",
        "    for v in revPaths:\n",
        "        v = v[::-1]\n",
        "        paths.append(v)\n",
        "\n",
        "    return paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Gb_YYySFt_"
      },
      "source": [
        "# Number of vertices\n",
        "n = 83\n",
        "\n",
        "# Number of pairs\n",
        "pairs = 0\n",
        "for i in paths:\n",
        "  for j in i:\n",
        "    pairs+=1\n",
        "\n",
        "# array of vectors is used\n",
        "# to store the graph\n",
        "# in the form of an adjacency list\n",
        "adj = [[] for i in range(len(paths))]\n",
        "\n",
        "for i in paths:\n",
        "  for j in i:\n",
        "    add_edge(adj, j[0], j[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnQWAxMBYx3S"
      },
      "source": [
        "shortest_paths = []\n",
        "\n",
        "for i in range(len(paths)):\n",
        "  for j in range(len(paths)):\n",
        "    if i!=j:\n",
        "      shortest_paths.append(getPaths(adj, n, i, j))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOYnyyg1dDK5"
      },
      "source": [
        "routingTable = []\n",
        "\n",
        "for j in range(100):\n",
        "  routes = []\n",
        "  for i in shortest_paths:\n",
        "    routes.append(random.choice(i))\n",
        "  routingTable.append(routes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NYI0HbjBo62"
      },
      "source": [
        "entropyTables = []\n",
        "\n",
        "for i in routingTable:\n",
        "  temp = []\n",
        "  for j in i:\n",
        "    temp.append(entropy(j))\n",
        "  entropyTables.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KZbWDo_FeLr"
      },
      "source": [
        "epochSize = len(connections[0])-1 # saját magukhoz nem vezet út\n",
        "# ent[0] - entropy of paths from 0 -> [1:82]\n",
        "ent = []\n",
        "\n",
        "for i in entropyTables:\n",
        "  temp = []\n",
        "  table = []\n",
        "  for j in range(len(i)):\n",
        "    temp.append(i[j])\n",
        "    if len(temp)==epochSize:\n",
        "      table.append(temp)\n",
        "      temp = []\n",
        "  ent.append(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q--VmfpZ19u"
      },
      "source": [
        "# Entrópiája a 100x82 routing táblának külön-külön\n",
        "# avgEntropy[0] - len = 82 -> minden táblának az átlagos entrópiája\n",
        "\n",
        "avgEntropy = []\n",
        "\n",
        "for i in ent:\n",
        "  avgIter = []\n",
        "  for j in i:\n",
        "    sum = 0\n",
        "    for z in j:\n",
        "      sum += z\n",
        "    mean = sum/len(j)\n",
        "    avgIter.append(mean)\n",
        "  avgEntropy.append(avgIter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ou_QuJMumkP"
      },
      "source": [
        "for i in len(avgEntropy[0]):\n",
        "  if avgEntropy[10][i] != avgEntropy[50][i]:\n",
        "    print(\"lol\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj89xb7l3TFn"
      },
      "source": [
        "x_axes = [*range(0, len(positions[0]), 1)]\n",
        "\n",
        "# plotting a line plot after changing it's width and height\n",
        "f = plt.figure()\n",
        "f.set_figwidth(25)\n",
        "f.set_figheight(15)\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('Nodes')\n",
        "# naming the y axis\n",
        "plt.ylabel('Entropy')\n",
        "\n",
        "# Blue\n",
        "plt.plot(x_axes, avgEntropy[99], marker='o')\n",
        "# Green\n",
        "plt.plot(x_axes, avgEntropy[50], marker='o')\n",
        "# Orange\n",
        "plt.plot(x_axes, avgEntropy[0], marker='o')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6YyhdIK3aDH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}